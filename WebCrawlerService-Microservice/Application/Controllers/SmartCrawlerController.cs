using System.Security.Claims;
using Microsoft.AspNetCore.Authorization;
using Microsoft.AspNetCore.Mvc;
using WebCrawlerService.Application.Services;
using WebCrawlerService.Application.Services.Crawl4AI;
using WebCrawlerService.Domain.Entities;
using WebCrawlerService.Domain.Enums;
using WebCrawlerService.Domain.Interfaces;
using WebCrawlerService.Domain.Models;

namespace WebCrawlerService.Application.Controllers;

/// <summary>
/// Controller for intelligent web crawling with natural language prompts
/// </summary>
[ApiController]
[Route("api/smart-crawler")]
[Authorize]
public class SmartCrawlerController : ControllerBase
{
    private readonly ISmartCrawlerOrchestrationService _orchestration;
    private readonly IRepository<PromptHistory> _promptHistoryRepo;
    private readonly IRepository<NavigationStrategy> _navigationStrategyRepo;
    private readonly IRepository<CrawlJob> _crawlJobRepo;
    private readonly IRepository<CrawlResult> _crawlResultRepo;
    private readonly ICrawlerMonitoringService _monitoringService;
    private readonly ILogger<SmartCrawlerController> _logger;

    public SmartCrawlerController(
        ISmartCrawlerOrchestrationService orchestration,
        IRepository<PromptHistory> promptHistoryRepo,
        IRepository<NavigationStrategy> navigationStrategyRepo,
        IRepository<CrawlJob> crawlJobRepo,
        IRepository<CrawlResult> crawlResultRepo,
        ICrawlerMonitoringService monitoringService,
        ILogger<SmartCrawlerController> logger)
    {
        _orchestration = orchestration;
        _promptHistoryRepo = promptHistoryRepo;
        _navigationStrategyRepo = navigationStrategyRepo;
        _crawlJobRepo = crawlJobRepo;
        _crawlResultRepo = crawlResultRepo;
        _monitoringService = monitoringService;
        _logger = logger;
    }

    /// <summary>
    /// Execute intelligent crawl with natural language prompt
    /// </summary>
    /// <param name="request">Crawl request with prompt and URL</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Crawl job result with conversation name</returns>
    [HttpPost("crawl")]
    [ProducesResponseType(typeof(IntelligentCrawlResponse), StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status400BadRequest)]
    [ProducesResponseType(StatusCodes.Status401Unauthorized)]
    public async Task<ActionResult<IntelligentCrawlResponse>> IntelligentCrawl(
        [FromBody] IntelligentCrawlRequest request,
        CancellationToken cancellationToken)
    {
        try
        {
            if (string.IsNullOrWhiteSpace(request.Prompt))
            {
                return BadRequest(new { error = "Prompt is required" });
            }

            if (string.IsNullOrWhiteSpace(request.Url) || !Uri.TryCreate(request.Url, UriKind.Absolute, out _))
            {
                return BadRequest(new { error = "Valid URL is required" });
            }

            // Use UserId from request if provided, otherwise from claims
            var userId = request.UserId != Guid.Empty
                ? request.UserId
                : Guid.Parse(User.FindFirstValue(ClaimTypes.NameIdentifier)!);

            _logger.LogInformation("User {UserId} initiated intelligent crawl. Prompt: '{Prompt}', URL: {Url}, AssignmentId: {AssignmentId}, GroupId: {GroupId}, ConversationId: {ConversationId}",
                userId, request.Prompt, request.Url, request.AssignmentId, request.GroupId, request.ConversationThreadId);

            var result = await _orchestration.ExecuteIntelligentCrawlAsync(
                userId,
                request.Prompt,
                request.Url,
                request.AssignmentId,
                request.GroupId,
                request.ConversationThreadId,
                cancellationToken
            );

            if (result.Success)
            {
                return Ok(new IntelligentCrawlResponse
                {
                    JobResult = result,
                    // Conversation name generated by Python/Gemini, received via Kafka
                    ConversationName = result.ConversationName ?? "New Conversation"
                });
            }
            else
            {
                if (!string.IsNullOrWhiteSpace(result.ErrorMessage) &&
                    result.ErrorMessage.Contains("quota", StringComparison.OrdinalIgnoreCase))
                {
                    return Ok(new IntelligentCrawlResponse
                    {
                        JobResult = result,
                        ConversationName = result.ConversationName
                    });
                }

                return BadRequest(new
                {
                    error = result.ErrorMessage ?? "Crawl failed",
                    jobId = result.JobId
                });
            }
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error processing intelligent crawl request");
            return StatusCode(500, new { error = "Internal server error" });
        }
    }

    /// <summary>
    /// Get crawl job status and results
    /// </summary>
    /// <param name="jobId">Job ID</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Job result</returns>
    [HttpGet("job/{jobId}")]
    [ProducesResponseType(typeof(CrawlJobResult), StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status404NotFound)]
    public async Task<ActionResult<CrawlJobResult>> GetJobStatus(
        Guid jobId,
        CancellationToken cancellationToken)
    {
        var result = await _orchestration.GetJobResultAsync(jobId, cancellationToken);

        if (result == null)
        {
            return NotFound(new { error = "Job not found" });
        }

        return Ok(result);
    }

    /// <summary>
    /// Get user's prompt history
    /// </summary>
    /// <param name="limit">Maximum number of records to return</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>List of prompt history records</returns>
    [HttpGet("history")]
    [ProducesResponseType(typeof(List<PromptHistoryDto>), StatusCodes.Status200OK)]
    public async Task<ActionResult<List<PromptHistoryDto>>> GetPromptHistory(
        [FromQuery] int limit = 50,
        CancellationToken cancellationToken = default)
    {
        var userId = Guid.Parse(User.FindFirstValue(ClaimTypes.NameIdentifier)!);

        var history = await _promptHistoryRepo.GetAsync(null, null, null, null, cancellationToken);

        var userHistory = history
            .Where(h => h.UserId == userId)
            .OrderByDescending(h => h.ProcessedAt)
            .Take(limit)
            .Select(h => new PromptHistoryDto
            {
                Id = h.Id,
                PromptText = h.PromptText,
                Type = h.Type.ToString(),
                ProcessedAt = h.ProcessedAt,
                CrawlJobId = h.CrawlJobId,
                ProcessingTimeMs = h.ProcessingTimeMs,
                Success = h.CrawlJobId.HasValue
            })
            .ToList();

        return Ok(userHistory);
    }

    /// <summary>
    /// Get learned navigation strategies for a domain
    /// </summary>
    /// <param name="domain">Domain name (e.g., "example.com")</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>List of navigation strategies</returns>
    [HttpGet("strategies")]
    [ProducesResponseType(typeof(List<NavigationStrategyDto>), StatusCodes.Status200OK)]
    public async Task<ActionResult<List<NavigationStrategyDto>>> GetNavigationStrategies(
        [FromQuery] string? domain = null,
        CancellationToken cancellationToken = default)
    {
        var strategies = await _navigationStrategyRepo.GetAsync(null, null, null, null, cancellationToken);

        var filtered = strategies
            .Where(s => s.IsActive && (string.IsNullOrEmpty(domain) || s.Domain == domain))
            .OrderByDescending(s => s.SuccessRate)
            .ThenByDescending(s => s.TimesUsed)
            .Select(s => new NavigationStrategyDto
            {
                Id = s.Id,
                Name = s.Name,
                Domain = s.Domain,
                Type = s.Type.ToString(),
                TimesUsed = s.TimesUsed,
                SuccessRate = s.SuccessRate,
                IsTemplate = s.IsTemplate,
                CreatedAt = s.CreatedAt
            })
            .ToList();

        return Ok(filtered);
    }

    /// <summary>
    /// Get detailed navigation strategy
    /// </summary>
    /// <param name="strategyId">Strategy ID</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Navigation strategy with steps</returns>
    [HttpGet("strategies/{strategyId}")]
    [ProducesResponseType(typeof(NavigationStrategyDetailDto), StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status404NotFound)]
    public async Task<ActionResult<NavigationStrategyDetailDto>> GetNavigationStrategyDetail(
        Guid strategyId,
        CancellationToken cancellationToken = default)
    {
        var strategy = await _navigationStrategyRepo.GetByIdAsync(strategyId);

        if (strategy == null)
        {
            return NotFound(new { error = "Strategy not found" });
        }

        return Ok(new NavigationStrategyDetailDto
        {
            Id = strategy.Id,
            Name = strategy.Name,
            Domain = strategy.Domain,
            UrlPattern = strategy.UrlPattern,
            Type = strategy.Type.ToString(),
            NavigationStepsJson = strategy.NavigationStepsJson,
            TimesUsed = strategy.TimesUsed,
            SuccessCount = strategy.SuccessCount,
            FailureCount = strategy.FailureCount,
            SuccessRate = strategy.SuccessRate,
            AverageExecutionTimeMs = strategy.AverageExecutionTimeMs,
            IsTemplate = strategy.IsTemplate,
            IsActive = strategy.IsActive,
            CreatedAt = strategy.CreatedAt,
            UpdatedAt = strategy.UpdatedAt
        });
    }

    /// <summary>
    /// Get user's crawl jobs
    /// </summary>
    /// <param name="limit">Maximum number of jobs to return</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>List of crawl jobs</returns>
    [HttpGet("jobs")]
    [ProducesResponseType(typeof(List<CrawlJobDto>), StatusCodes.Status200OK)]
    public async Task<ActionResult<List<CrawlJobDto>>> GetCrawlJobs(
        [FromQuery] int limit = 50,
        CancellationToken cancellationToken = default)
    {
        var userId = Guid.Parse(User.FindFirstValue(ClaimTypes.NameIdentifier)!);

        var jobs = await _crawlJobRepo.GetAsync(null, null, null, null, cancellationToken);

        var userJobs = jobs
            .Where(j => j.UserId == userId)
            .OrderByDescending(j => j.CreatedAt)
            .Take(limit)
            .Select(j => new CrawlJobDto
            {
                Id = j.Id,
                Status = j.Status.ToString(),
                CrawlerType = j.CrawlerType.ToString(),
                UserPrompt = j.UserPrompt,
                ResultCount = j.ResultCount,
                CreatedAt = j.CreatedAt,
                CompletedAt = j.CompletedAt,
                ErrorMessage = j.ErrorMessage
            })
            .ToList();

        return Ok(userJobs);
    }

    /// <summary>
    /// Get paginated crawled results for a job
    /// </summary>
    /// <param name="jobId">Job ID</param>
    /// <param name="page">Page number (default: 1)</param>
    /// <param name="pageSize">Page size (default: 50)</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Paginated list of crawl results</returns>
    [HttpGet("job/{jobId}/results")]
    [AllowAnonymous] // Allow internal microservice calls from ClassroomService
    [ProducesResponseType(typeof(List<WebCrawlerService.Application.DTOs.CrawlResultDto>), StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status404NotFound)]
    public async Task<ActionResult<List<WebCrawlerService.Application.DTOs.CrawlResultDto>>> GetJobResults(
        Guid jobId,
        [FromQuery] int page = 1,
        [FromQuery] int pageSize = 50,
        CancellationToken cancellationToken = default)
    {
        var job = await _crawlJobRepo.GetByIdAsync(jobId, cancellationToken);
        if (job == null)
        {
            return NotFound(new { error = "Job not found" });
        }

        // Ensure user owns this job (skip authorization for anonymous internal service calls)
        if (User.Identity?.IsAuthenticated == true)
        {
            var userIdClaim = User.FindFirstValue(ClaimTypes.NameIdentifier);
            if (userIdClaim != null && Guid.TryParse(userIdClaim, out var userId))
            {
                if (job.UserId != userId && !User.IsInRole("Admin") && !User.IsInRole("Staff"))
                {
                    return Forbid();
                }
            }
        }

        var results = await _crawlResultRepo.GetAsync(null, null, null, null, cancellationToken);
        var jobResults = results
            .Where(r => r.CrawlJobId == jobId)
            .OrderByDescending(r => r.CrawledAt)
            .Skip((page - 1) * pageSize)
            .Take(pageSize)
            .Select(r => new WebCrawlerService.Application.DTOs.CrawlResultDto
            {
                Id = r.Id,
                Url = r.Url,
                ExtractedData = WebCrawlerService.Application.DTOs.CrawlResultDto.ParseExtractedData(r.ExtractedDataJson),
                Title = r.Title,
                HttpStatusCode = r.HttpStatusCode,
                CrawledAt = r.CrawledAt,
                ResponseTimeMs = r.ResponseTimeMs,
                ExtractionConfidence = r.ExtractionConfidence,
                ErrorMessage = r.ErrorMessage,
                ContentSize = r.ContentSize,
                PromptUsed = r.PromptUsed
            })
            .ToList();

        return Ok(jobResults);
    }

    /// <summary>
    /// Get real-time statistics for a job
    /// </summary>
    /// <param name="jobId">Job ID</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>Job statistics</returns>
    [HttpGet("job/{jobId}/stats")]
    [ProducesResponseType(typeof(WebCrawlerService.Application.DTOs.JobStatsDto), StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status404NotFound)]
    public async Task<ActionResult<WebCrawlerService.Application.DTOs.JobStatsDto>> GetJobStats(
        Guid jobId,
        CancellationToken cancellationToken = default)
    {
        var job = await _crawlJobRepo.GetByIdAsync(jobId, cancellationToken);
        if (job == null)
        {
            return NotFound(new { error = "Job not found" });
        }

        // Ensure user owns this job
        var userId = Guid.Parse(User.FindFirstValue(ClaimTypes.NameIdentifier)!);
        if (job.UserId != userId && !User.IsInRole("Admin") && !User.IsInRole("Staff"))
        {
            return Forbid();
        }

        var stats = await _monitoringService.GetJobStatsAsync(jobId, cancellationToken);
        if (stats == null)
        {
            return NotFound(new { error = "Job stats not available" });
        }

        return Ok(stats);
    }

    /// <summary>
    /// Export job results in various formats
    /// </summary>
    /// <param name="jobId">Job ID</param>
    /// <param name="format">Export format (json, csv)</param>
    /// <param name="cancellationToken">Cancellation token</param>
    /// <returns>File download</returns>
    [HttpGet("job/{jobId}/export")]
    [ProducesResponseType(typeof(FileContentResult), StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status404NotFound)]
    public async Task<IActionResult> ExportJobResults(
        Guid jobId,
        [FromQuery] string format = "json",
        CancellationToken cancellationToken = default)
    {
        var job = await _crawlJobRepo.GetByIdAsync(jobId, cancellationToken);
        if (job == null)
        {
            return NotFound(new { error = "Job not found" });
        }

        // Ensure user owns this job
        var userId = Guid.Parse(User.FindFirstValue(ClaimTypes.NameIdentifier)!);
        if (job.UserId != userId && !User.IsInRole("Admin") && !User.IsInRole("Staff"))
        {
            return Forbid();
        }

        var results = await _crawlResultRepo.GetAsync(null, null, null, null, cancellationToken);
        var jobResults = results
            .Where(r => r.CrawlJobId == jobId)
            .OrderByDescending(r => r.CrawledAt)
            .ToList();

        if (format.ToLower() == "json")
        {
            var exportData = jobResults.Select(r => new
            {
                url = r.Url,
                extractedData = WebCrawlerService.Application.DTOs.CrawlResultDto.ParseExtractedData(r.ExtractedDataJson),
                title = r.Title,
                statusCode = r.HttpStatusCode,
                crawledAt = r.CrawledAt,
                responseTimeMs = r.ResponseTimeMs,
                contentSize = r.ContentSize
            });

            var json = System.Text.Json.JsonSerializer.Serialize(exportData, new System.Text.Json.JsonSerializerOptions
            {
                WriteIndented = true
            });

            return File(System.Text.Encoding.UTF8.GetBytes(json), "application/json", $"job_{jobId}_results.json");
        }
        else if (format.ToLower() == "csv")
        {
            var csv = new System.Text.StringBuilder();
            csv.AppendLine("URL,Title,StatusCode,CrawledAt,ResponseTimeMs,ContentSize");

            foreach (var result in jobResults)
            {
                csv.AppendLine($"\"{result.Url}\",\"{result.Title}\",{result.HttpStatusCode},{result.CrawledAt:o},{result.ResponseTimeMs},{result.ContentSize}");
            }

            return File(System.Text.Encoding.UTF8.GetBytes(csv.ToString()), "text/csv", $"job_{jobId}_results.csv");
        }

        return BadRequest(new { error = "Unsupported format. Use 'json' or 'csv'." });
    }
}

// DTOs
public record IntelligentCrawlRequest(
    string Prompt,
    string Url,
    Guid UserId,
    Guid? AssignmentId = null,
    Guid? GroupId = null,
    Guid? ConversationThreadId = null);

public class PromptHistoryDto
{
    public Guid Id { get; set; }
    public string PromptText { get; set; } = null!;
    public string Type { get; set; } = null!;
    public DateTime ProcessedAt { get; set; }
    public Guid? CrawlJobId { get; set; }
    public int ProcessingTimeMs { get; set; }
    public bool Success { get; set; }
}

public class NavigationStrategyDto
{
    public Guid Id { get; set; }
    public string Name { get; set; } = null!;
    public string Domain { get; set; } = null!;
    public string Type { get; set; } = null!;
    public int TimesUsed { get; set; }
    public double SuccessRate { get; set; }
    public bool IsTemplate { get; set; }
    public DateTime CreatedAt { get; set; }
}

public class NavigationStrategyDetailDto : NavigationStrategyDto
{
    public string UrlPattern { get; set; } = null!;
    public string NavigationStepsJson { get; set; } = null!;
    public int SuccessCount { get; set; }
    public int FailureCount { get; set; }
    public double AverageExecutionTimeMs { get; set; }
    public bool IsActive { get; set; }
    public DateTime? UpdatedAt { get; set; }
}

public class CrawlJobDto
{
    public Guid Id { get; set; }
    public string Status { get; set; } = null!;
    public string CrawlerType { get; set; } = null!;
    public string? UserPrompt { get; set; }
    public int ResultCount { get; set; }
    public DateTime CreatedAt { get; set; }
    public DateTime? CompletedAt { get; set; }
    public string? ErrorMessage { get; set; }
}

/// <summary>
/// Response for intelligent crawl endpoint including conversation name
/// </summary>
public class IntelligentCrawlResponse
{
    /// <summary>
    /// The crawl job result
    /// </summary>
    public CrawlJobResult JobResult { get; set; } = null!;
    
    /// <summary>
    /// AI-generated or summarized conversation name from the user's prompt
    /// </summary>
    public string? ConversationName { get; set; }
}
